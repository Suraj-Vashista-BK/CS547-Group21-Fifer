{"cells":[{"cell_type":"markdown","metadata":{"id":"VVWVysITSiAP"},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTZjTTGtRJKq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import seaborn as sns\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","import warnings\n","import random\n","import os\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dropout, GRU\n","import itertools\n","from sklearn.preprocessing import MinMaxScaler\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"5_Uaehe4SrI2"},"source":["# Data Loading And Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"elapsed":2514,"status":"ok","timestamp":1670647278512,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"nfYggC79Ricf","outputId":"f1735266-2b1c-4da3-bfe5-0bdeca83e548"},"outputs":[{"output_type":"stream","name":"stdout","text":["local file not found; accessing Google Drive\n"]},{"output_type":"execute_result","data":{"text/plain":["          Area Type                           Area Name         Date  Year   \\\n","0              State                          California  01/01/1976   1976   \n","1              State                          California  01/01/1976   1976   \n","2             County                  Los Angeles County  01/01/1976   1976   \n","3             County                  Los Angeles County  01/01/1976   1976   \n","4  Metropolitan Area  Los Angeles-Long Beach-Glendale MD  01/01/1976   1976   \n","\n","     Month Seasonally Adjusted (Y/N)  Status (Preliminary / Final)   \\\n","0  January                          N                         Final   \n","1  January                          Y                         Final   \n","2  January                          N                         Final   \n","3  January                          Y                         Final   \n","4  January                          N                         Final   \n","\n","   Labor Force  Employment   Unemployment   Unemployment Rate   \n","0      9672362      8668016        1004346               0.104  \n","1      9774280      8875685         898595               0.092  \n","2      3364151      3040058         324093               0.096  \n","3      3381856      3081806         300050               0.089  \n","4      3364151      3040058         324093               0.096  "],"text/html":["\n","  <div id=\"df-72836783-e56e-4750-b7d9-9683016ba9f3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area Type</th>\n","      <th>Area Name</th>\n","      <th>Date</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Seasonally Adjusted (Y/N)</th>\n","      <th>Status (Preliminary / Final)</th>\n","      <th>Labor Force</th>\n","      <th>Employment</th>\n","      <th>Unemployment</th>\n","      <th>Unemployment Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>9672362</td>\n","      <td>8668016</td>\n","      <td>1004346</td>\n","      <td>0.104</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>9774280</td>\n","      <td>8875685</td>\n","      <td>898595</td>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>3381856</td>\n","      <td>3081806</td>\n","      <td>300050</td>\n","      <td>0.089</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metropolitan Area</td>\n","      <td>Los Angeles-Long Beach-Glendale MD</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72836783-e56e-4750-b7d9-9683016ba9f3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-72836783-e56e-4750-b7d9-9683016ba9f3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-72836783-e56e-4750-b7d9-9683016ba9f3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["# Try to load the dataset from the local file, If not possible, then defaults to google drive version\n","def getfile(location_pair,**kwargs):\n","    (loc,gdrive)=location_pair\n","    try:\n","        out=pd.read_csv(loc,**kwargs)\n","    except FileNotFoundError:\n","        print(\"local file not found; accessing Google Drive\")\n","        loc = 'https://drive.google.com/uc?export=download&id='+gdrive.split('/')[-2]\n","        out = pd.read_csv(loc,**kwargs)\n","    return out\n","\n","fname=(\"Local_Area_Unemployment_Statistics__LAUS_.csv\",\"https://drive.google.com/file/d/1xoDHEKiN-y4QyZNET8SdlVRSsgW_7TLy/view?usp=sharing\")\n","raw_data=getfile(fname)\n","raw_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1670647336299,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"wiDTSePiSnBI","outputId":"12f48bb3-ed96-418c-fd57-52bfd21e170d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Area Type                           Area Name        Date  Year   \\\n","0              State                          California 1976-01-01   1976   \n","1              State                          California 1976-01-01   1976   \n","2             County                  Los Angeles County 1976-01-01   1976   \n","3             County                  Los Angeles County 1976-01-01   1976   \n","4  Metropolitan Area  Los Angeles-Long Beach-Glendale MD 1976-01-01   1976   \n","\n","     Month Seasonally Adjusted (Y/N)  Status (Preliminary / Final)   \\\n","0  January                          N                         Final   \n","1  January                          Y                         Final   \n","2  January                          N                         Final   \n","3  January                          Y                         Final   \n","4  January                          N                         Final   \n","\n","   Labor Force  Employment   Unemployment   Unemployment Rate   \\\n","0      9672362      8668016        1004346               0.104   \n","1      9774280      8875685         898595               0.092   \n","2      3364151      3040058         324093               0.096   \n","3      3381856      3081806         300050               0.089   \n","4      3364151      3040058         324093               0.096   \n","\n","                   ts  Employment Rate  \n","0  189302400000000000         0.896163  \n","1  189302400000000000         0.908065  \n","2  189302400000000000         0.903663  \n","3  189302400000000000         0.911277  \n","4  189302400000000000         0.903663  "],"text/html":["\n","  <div id=\"df-7f892391-dfc6-4d96-aa67-ad4bcf119ba7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area Type</th>\n","      <th>Area Name</th>\n","      <th>Date</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Seasonally Adjusted (Y/N)</th>\n","      <th>Status (Preliminary / Final)</th>\n","      <th>Labor Force</th>\n","      <th>Employment</th>\n","      <th>Unemployment</th>\n","      <th>Unemployment Rate</th>\n","      <th>ts</th>\n","      <th>Employment Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>9672362</td>\n","      <td>8668016</td>\n","      <td>1004346</td>\n","      <td>0.104</td>\n","      <td>189302400000000000</td>\n","      <td>0.896163</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>9774280</td>\n","      <td>8875685</td>\n","      <td>898595</td>\n","      <td>0.092</td>\n","      <td>189302400000000000</td>\n","      <td>0.908065</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","      <td>189302400000000000</td>\n","      <td>0.903663</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>3381856</td>\n","      <td>3081806</td>\n","      <td>300050</td>\n","      <td>0.089</td>\n","      <td>189302400000000000</td>\n","      <td>0.911277</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metropolitan Area</td>\n","      <td>Los Angeles-Long Beach-Glendale MD</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","      <td>189302400000000000</td>\n","      <td>0.903663</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f892391-dfc6-4d96-aa67-ad4bcf119ba7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7f892391-dfc6-4d96-aa67-ad4bcf119ba7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7f892391-dfc6-4d96-aa67-ad4bcf119ba7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["raw_data['Date']= pd.to_datetime(raw_data['Date'])\n","raw_data['ts'] = raw_data.Date.values.astype(np.int64) # convert datetime to pandas timestamps\n","raw_data['Employment Rate']=raw_data['Employment ']/raw_data['Labor Force']\n","raw_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWlTUtY0Schk"},"outputs":[],"source":["#Loading the necessary columns\n","raw_data.columns = ['Area Type', 'Area Name', 'Date', 'Year', 'Month',\n","       'Seasonally Adjusted (Y/N)', 'Status (Preliminary / Final)',\n","       'Labor Force', 'Employment', 'Unemployment', 'Unemployment Rate','ts','Employment Rate']\n","subData_State = raw_data.loc[(raw_data['Area Type']=='State')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1670647337991,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"ZuAcw8pTUEnp","outputId":"e4583b77-ab2b-48da-b736-01e8ce34be36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f5ac7a16940>"]},"metadata":{},"execution_count":10},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Checking a plot of unemployment rate over the years\n","\n","graphPlotter = subData_State[['Date','Unemployment Rate']]\n","graphPlotter.set_index([\"Date\"], inplace=True)\n","graphPlotter.plot(title=\"California Unemployment Rate Over 45 Years\\n\", ylabel=\"rate\", xlabel=\"Year\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670647337992,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"T5CayCAVRxO_","outputId":"2d4bf2db-c5eb-4ed8-b744-d65f0633e818"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1122 entries, 0 to 178345\n","Data columns (total 13 columns):\n"," #   Column                        Non-Null Count  Dtype         \n","---  ------                        --------------  -----         \n"," 0   Area Type                     1122 non-null   object        \n"," 1   Area Name                     1122 non-null   object        \n"," 2   Date                          1122 non-null   datetime64[ns]\n"," 3   Year                          1122 non-null   int64         \n"," 4   Month                         1122 non-null   object        \n"," 5   Seasonally Adjusted (Y/N)     1122 non-null   object        \n"," 6   Status (Preliminary / Final)  1122 non-null   object        \n"," 7   Labor Force                   1122 non-null   int64         \n"," 8   Employment                    1122 non-null   int64         \n"," 9   Unemployment                  1122 non-null   int64         \n"," 10  Unemployment Rate             1122 non-null   float64       \n"," 11  ts                            1122 non-null   int64         \n"," 12  Employment Rate               1122 non-null   float64       \n","dtypes: datetime64[ns](1), float64(2), int64(5), object(5)\n","memory usage: 122.7+ KB\n"]}],"source":["subData_State.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670647338125,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"t6KpQObFYtHc","outputId":"007560d5-72e0-475d-c108-7f149a0411d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Unemployment Rate\n","Date                         \n","1976-01-01              0.104\n","1976-01-01              0.092\n","1977-01-01              0.099\n","1977-01-01              0.092\n","1978-01-01              0.083"],"text/html":["\n","  <div id=\"df-1f3a029f-7cd4-436f-ab06-df28d2340ba1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unemployment Rate</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1976-01-01</th>\n","      <td>0.104</td>\n","    </tr>\n","    <tr>\n","      <th>1976-01-01</th>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>1977-01-01</th>\n","      <td>0.099</td>\n","    </tr>\n","    <tr>\n","      <th>1977-01-01</th>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>1978-01-01</th>\n","      <td>0.083</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f3a029f-7cd4-436f-ab06-df28d2340ba1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1f3a029f-7cd4-436f-ab06-df28d2340ba1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1f3a029f-7cd4-436f-ab06-df28d2340ba1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["graphPlotter.head()"]},{"cell_type":"markdown","metadata":{"id":"3Axa8WDHAUNK"},"source":["Normalization of Data and splitting of data & converting into time step data for time series forcasting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670647339094,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"x0mHaNbQXRu9","outputId":"e28adc97-3350-4562-b6ae-0a94e5db2c2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.104\n","1    0.092\n","2    0.099\n","3    0.092\n","4    0.083\n","Name: Unemployment Rate, dtype: float64"]},"metadata":{},"execution_count":13}],"source":["model_data = graphPlotter.reset_index()['Unemployment Rate']\n","model_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670647339471,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"2HPsF7aAXk2D","outputId":"c275c738-bfe5-4f3d-e82d-1a348ffae92b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.54761905],\n","       [0.45238095],\n","       [0.50793651],\n","       ...,\n","       [0.45238095],\n","       [0.1031746 ],\n","       [0.18253968]])"]},"metadata":{},"execution_count":14}],"source":["# using sklearn MinMaxScaler for normalizing thr data\n","scaler=MinMaxScaler(feature_range=(0,1))\n","model_data_normalized=scaler.fit_transform(np.array(model_data).reshape(-1,1))\n","model_data_normalized"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1670647339602,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"iBtIxOgvXxG-","outputId":"d55bb410-899d-430d-9f66-de88ccb83e75"},"outputs":[{"output_type":"stream","name":"stdout","text":["729 393\n"]}],"source":["training_size=int(len(model_data_normalized)*0.65)\n","test_size=len(model_data_normalized)-training_size\n","train_data,test_data=model_data_normalized[0:training_size,:],model_data_normalized[training_size:len(model_data_normalized),:1]\n","print(training_size,test_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMx3kwa-X7T4"},"outputs":[],"source":["def create_dataset(dataset, time_step=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-time_step-1):\n","        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n","        dataX.append(a)\n","        dataY.append(dataset[i + time_step, 0])\n","    return np.array(dataX), np.array(dataY)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1670647340647,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"1geI8IF4YCPK","outputId":"041eddc8-aca5-492a-ea60-e78719ce5231"},"outputs":[{"output_type":"stream","name":"stdout","text":["(628, 100) (628,)\n","(292, 100) (292,)\n"]}],"source":["# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n","time_step = 100\n","X_train, y_train = create_dataset(train_data, time_step)\n","X_test, ytest = create_dataset(test_data, time_step)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, ytest.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN7Asj-4YPJR"},"outputs":[],"source":["# reshape input to be [samples, time steps, features] which is required for LSTM\n","X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"]},{"cell_type":"markdown","metadata":{"id":"1SwSbzKYBgoa"},"source":["#Traing Model using LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CqHZc438_3kY"},"outputs":[],"source":["#First model\n","model = Sequential()\n","model.add(LSTM(units=32, return_sequences=True))\n","model.add(LSTM(units=32, return_sequences=False))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37616,"status":"ok","timestamp":1670647379429,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"510Z5VuzAFnq","outputId":"893ca1f7-3bb9-4ae4-9830-baabf3eb2eac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","20/20 [==============================] - 7s 133ms/step - loss: 0.0398 - val_loss: 0.0276\n","Epoch 2/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.0314 - val_loss: 0.0226\n","Epoch 3/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0272 - val_loss: 0.0184\n","Epoch 4/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0242 - val_loss: 0.0162\n","Epoch 5/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0227 - val_loss: 0.0168\n","Epoch 6/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.0225 - val_loss: 0.0190\n","Epoch 7/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0218 - val_loss: 0.0269\n","Epoch 8/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0219 - val_loss: 0.0143\n","Epoch 9/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0207 - val_loss: 0.0166\n","Epoch 10/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0204 - val_loss: 0.0133\n","Epoch 11/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0195 - val_loss: 0.0129\n","Epoch 12/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0188 - val_loss: 0.0124\n","Epoch 13/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.0182 - val_loss: 0.0122\n","Epoch 14/20\n","20/20 [==============================] - 2s 85ms/step - loss: 0.0178 - val_loss: 0.0124\n","Epoch 15/20\n","20/20 [==============================] - 2s 119ms/step - loss: 0.0173 - val_loss: 0.0113\n","Epoch 16/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0169 - val_loss: 0.0107\n","Epoch 17/20\n","20/20 [==============================] - 2s 77ms/step - loss: 0.0165 - val_loss: 0.0118\n","Epoch 18/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0158 - val_loss: 0.0104\n","Epoch 19/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.0155 - val_loss: 0.0094\n","Epoch 20/20\n","20/20 [==============================] - 2s 76ms/step - loss: 0.0147 - val_loss: 0.0093\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5ac4b27070>"]},"metadata":{},"execution_count":20}],"source":["model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=20,batch_size=32,verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1097,"status":"ok","timestamp":1670647386411,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"5FvAsQ6oAW8z","outputId":"bd0244be-a814-4567-d3db-0ff01b022b89"},"outputs":[{"output_type":"stream","name":"stdout","text":["20/20 [==============================] - 0s 18ms/step\n","10/10 [==============================] - 0s 17ms/step\n"]}],"source":["### Lets Do the prediction and check performance metrics\n","train_predict=model.predict(X_train)\n","test_predict=model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rOsGENoAW80"},"outputs":[],"source":["##Transformback to original form\n","train_predict=scaler.inverse_transform(train_predict)\n","test_predict=scaler.inverse_transform(test_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dfzqy5FDwrI"},"outputs":[],"source":["ytest = scaler.inverse_transform(np.array(ytest).reshape(-1,1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670647387380,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"RLhBFIoS7q4I","outputId":"9c4d47a6-e370-4c59-ae81-86b3c8ec5866"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.28709185326221215"]},"metadata":{},"execution_count":26}],"source":["### Calculate RMSE performance metrics\n","import math\n","from sklearn.metrics import mean_squared_error\n","math.sqrt(mean_squared_error(y_train,train_predict))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1670647388005,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"},"user_tz":360},"id":"WtX1KsTV7tHb","outputId":"0b3ea705-df76-4d7f-ff9e-fd46de66ba1f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.01212347348689464"]},"metadata":{},"execution_count":27}],"source":["### Test Data RMSE\n","math.sqrt(mean_squared_error(ytest,test_predict))"]},{"cell_type":"markdown","metadata":{"id":"mM21c-pixg-F"},"source":["# Hyper-Parameter Tuning with mini batch training \n"]},{"cell_type":"markdown","metadata":{"id":"MdkRCBqe_zMG"},"source":["using 3 optimizers"]},{"cell_type":"markdown","metadata":{"id":"kYoI8KjsVA7j"},"source":["## Using Adam optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaryftBk5YCE"},"outputs":[],"source":["\n","def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'Adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stopping, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nWQq-555YEZ","executionInfo":{"status":"ok","timestamp":1670648022131,"user_tz":360,"elapsed":629429,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"2fc2f742-16fe-478d-d635-d5867f91e54e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03891, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03891 to 0.03288, saving model to best_model.h5\n","\n","Epoch 3: val_loss did not improve from 0.03288\n","\n","Epoch 4: val_loss improved from 0.03288 to 0.02922, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02922 to 0.02688, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02688\n","\n","Epoch 7: val_loss improved from 0.02688 to 0.02592, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02592 to 0.02477, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02477 to 0.02440, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02440 to 0.02287, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02287\n","\n","Epoch 12: val_loss did not improve from 0.02287\n","\n","Epoch 13: val_loss improved from 0.02287 to 0.02172, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02172 to 0.02163, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.02163 to 0.02056, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.02056\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.019265873357653618, 0.13880155980587006] and test accuracy: [0.049662332981824875, 0.2228504717350006]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03579, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03579 to 0.03388, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03388 to 0.03214, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03214 to 0.03047, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03047 to 0.02939, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02939\n","\n","Epoch 7: val_loss improved from 0.02939 to 0.02674, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02674\n","\n","Epoch 9: val_loss did not improve from 0.02674\n","\n","Epoch 10: val_loss improved from 0.02674 to 0.02638, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02638 to 0.02607, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02607 to 0.02540, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02540 to 0.02522, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.02522\n","\n","Epoch 15: val_loss improved from 0.02522 to 0.02354, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.02354\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.024296879768371582, 0.155874565243721] and test accuracy: [0.04204556345939636, 0.20505015552043915]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03810, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03810 to 0.03585, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03585 to 0.03489, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03489 to 0.03448, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03448 to 0.03280, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03280 to 0.03099, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03099 to 0.02880, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02880\n","\n","Epoch 9: val_loss improved from 0.02880 to 0.02781, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02781 to 0.02651, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02651\n","\n","Epoch 12: val_loss improved from 0.02651 to 0.02639, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02639\n","\n","Epoch 14: val_loss improved from 0.02639 to 0.02543, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02543\n","\n","Epoch 16: val_loss improved from 0.02543 to 0.02513, saving model to best_model.h5\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.024292223155498505, 0.15585961937904358] and test accuracy: [0.07642006129026413, 0.2764417827129364]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03262, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03262 to 0.03084, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03084 to 0.02728, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.02728 to 0.02610, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02610 to 0.02512, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02512 to 0.02262, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02262 to 0.02188, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02188\n","\n","Epoch 9: val_loss did not improve from 0.02188\n","\n","Epoch 10: val_loss improved from 0.02188 to 0.02076, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02076 to 0.01922, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.01922 to 0.01843, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.01843 to 0.01686, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.01686 to 0.01648, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.01648 to 0.01623, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.01623\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.01524004340171814, 0.12345056980848312] and test accuracy: [0.04635889083147049, 0.21531115472316742]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03589, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03589 to 0.03384, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03384 to 0.03302, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03302 to 0.03002, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03002 to 0.02769, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02769\n","\n","Epoch 7: val_loss improved from 0.02769 to 0.02610, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02610 to 0.02520, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02520 to 0.02341, saving model to best_model.h5\n","\n","Epoch 10: val_loss did not improve from 0.02341\n","\n","Epoch 11: val_loss improved from 0.02341 to 0.02192, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02192 to 0.02167, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02167 to 0.02000, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.02000\n","\n","Epoch 15: val_loss improved from 0.02000 to 0.01886, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.01886\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.01869172416627407, 0.13671767711639404] and test accuracy: [0.048098187893629074, 0.21931299567222595]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03743, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03743 to 0.03533, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03533 to 0.03356, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03356 to 0.02997, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02997 to 0.02950, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02950 to 0.02575, saving model to best_model.h5\n","\n","Epoch 7: val_loss did not improve from 0.02575\n","\n","Epoch 8: val_loss improved from 0.02575 to 0.02520, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02520 to 0.02405, saving model to best_model.h5\n","\n","Epoch 10: val_loss did not improve from 0.02405\n","\n","Epoch 11: val_loss did not improve from 0.02405\n","\n","Epoch 12: val_loss improved from 0.02405 to 0.02252, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02252\n","\n","Epoch 14: val_loss did not improve from 0.02252\n","\n","Epoch 15: val_loss improved from 0.02252 to 0.02236, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.02236 to 0.02130, saving model to best_model.h5\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.020254669710993767, 0.14231890439987183] and test accuracy: [0.07454673200845718, 0.2730324864387512]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"o7sca14I5YGW","executionInfo":{"status":"ok","timestamp":1670648093109,"user_tz":360,"elapsed":125,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"c2df7ff1-12ad-4c06-d6a9-96d9576ce6cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","1  True  False  False  16   8  0.2   \n","3  True  False  False  32   4  0.2   \n","4  True  False  False  32   8  0.2   \n","0  True  False  False  16   4  0.2   \n","5  True  False  False  32  16  0.2   \n","2  True  False  False  16  16  0.2   \n","\n","                                             6  \\\n","1    [0.024296879768371582, 0.155874565243721]   \n","3   [0.01524004340171814, 0.12345056980848312]   \n","4   [0.01869172416627407, 0.13671767711639404]   \n","0  [0.019265873357653618, 0.13880155980587006]   \n","5  [0.020254669710993767, 0.14231890439987183]   \n","2  [0.024292223155498505, 0.15585961937904358]   \n","\n","                                             7  \n","1   [0.04204556345939636, 0.20505015552043915]  \n","3   [0.04635889083147049, 0.21531115472316742]  \n","4  [0.048098187893629074, 0.21931299567222595]  \n","0   [0.049662332981824875, 0.2228504717350006]  \n","5    [0.07454673200845718, 0.2730324864387512]  \n","2    [0.07642006129026413, 0.2764417827129364]  "],"text/html":["\n","  <div id=\"df-6abbbdb5-51c1-41d1-8b31-85c1c92a3989\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.024296879768371582, 0.155874565243721]</td>\n","      <td>[0.04204556345939636, 0.20505015552043915]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.01524004340171814, 0.12345056980848312]</td>\n","      <td>[0.04635889083147049, 0.21531115472316742]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.01869172416627407, 0.13671767711639404]</td>\n","      <td>[0.048098187893629074, 0.21931299567222595]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.019265873357653618, 0.13880155980587006]</td>\n","      <td>[0.049662332981824875, 0.2228504717350006]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.020254669710993767, 0.14231890439987183]</td>\n","      <td>[0.07454673200845718, 0.2730324864387512]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.024292223155498505, 0.15585961937904358]</td>\n","      <td>[0.07642006129026413, 0.2764417827129364]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6abbbdb5-51c1-41d1-8b31-85c1c92a3989')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6abbbdb5-51c1-41d1-8b31-85c1c92a3989 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6abbbdb5-51c1-41d1-8b31-85c1c92a3989');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ej16nO-tCy6y","executionInfo":{"status":"ok","timestamp":1670648095360,"user_tz":360,"elapsed":1325,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"913f22ac-ec0e-4b9f-c7f4-0ca3e1b32f15"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 1s 19ms/step - loss: 0.0473\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMY1_WTnCMsC","executionInfo":{"status":"ok","timestamp":1670648844732,"user_tz":360,"elapsed":116,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"f3772021-2eeb-481c-f08f-452d7ad9bf0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 16\n"," n_batch_size = 16\n"," dropout = 0.2\n","**************************\n","Results Before Tunning:\n"," Test Set RMSE: 0.0473\n","\n","Results After Tunning:\n"," Test Set RMSE: [0.0445 0.211 ]\n","\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results Before Tuning:\\n Test Set RMSE: {np.round(results, 4)}\\n')\n","print(f'Results After Tuning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')"]},{"cell_type":"markdown","metadata":{"id":"UeqzrN95VLzH"},"source":["## Using Adagrad optimizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DVCg5CbxD2S"},"outputs":[],"source":["def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'Adagrad', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stopping, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuXHtFnjxD2p","executionInfo":{"status":"ok","timestamp":1670648829423,"user_tz":360,"elapsed":727938,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"33b798c9-3640-411b-adfa-ca977f02aeb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04979, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04979 to 0.03760, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03760 to 0.03561, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03561 to 0.03486, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03486 to 0.03475, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03475 to 0.03466, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03466 to 0.03461, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03461 to 0.03456, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03456 to 0.03442, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03442 to 0.03439, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03439 to 0.03429, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03429 to 0.03429, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.03429\n","\n","Epoch 14: val_loss did not improve from 0.03429\n","\n","Epoch 15: val_loss did not improve from 0.03429\n","\n","Epoch 16: val_loss improved from 0.03429 to 0.03424, saving model to best_model.h5\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.032101985067129135, 0.17917026579380035] and test accuracy: [0.049034446477890015, 0.2214372307062149]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.07038, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.07038 to 0.04993, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.04993 to 0.04121, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.04121 to 0.03747, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03747 to 0.03587, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03587 to 0.03511, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03511 to 0.03457, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03457 to 0.03438, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03438 to 0.03424, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03424 to 0.03412, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03412 to 0.03397, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.03397\n","\n","Epoch 13: val_loss did not improve from 0.03397\n","\n","Epoch 14: val_loss improved from 0.03397 to 0.03397, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03397 to 0.03389, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03389 to 0.03384, saving model to best_model.h5\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.031671538949012756, 0.17796500027179718] and test accuracy: [0.04842395335435867, 0.22005443274974823]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.08524, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.08524 to 0.06809, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.06809 to 0.05777, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.05777 to 0.05089, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.05089 to 0.04601, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.04601 to 0.04274, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.04274 to 0.04044, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.04044 to 0.03879, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03879 to 0.03755, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03755 to 0.03671, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03671 to 0.03611, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03611 to 0.03567, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03567 to 0.03540, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03540 to 0.03514, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03514 to 0.03498, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03498 to 0.03485, saving model to best_model.h5\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.03252781182527542, 0.18035468459129333] and test accuracy: [0.04450133815407753, 0.21095339953899384]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04285, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04285 to 0.03520, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03520 to 0.03427, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03427 to 0.03422, saving model to best_model.h5\n","\n","Epoch 5: val_loss did not improve from 0.03422\n","\n","Epoch 6: val_loss improved from 0.03422 to 0.03401, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03401 to 0.03395, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03395 to 0.03392, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03392 to 0.03391, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03391 to 0.03389, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03389 to 0.03380, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03380 to 0.03376, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03376 to 0.03368, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03368 to 0.03359, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03359 to 0.03353, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03353 to 0.03351, saving model to best_model.h5\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.031417105346918106, 0.17724871635437012] and test accuracy: [0.04960188269615173, 0.22271479666233063]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.05944, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.05944 to 0.04150, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.04150 to 0.03635, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03635 to 0.03514, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03514 to 0.03489, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03489 to 0.03480, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03480 to 0.03465, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03465 to 0.03456, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03456 to 0.03444, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03444 to 0.03442, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03442 to 0.03434, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03434 to 0.03432, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03432 to 0.03419, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.03419\n","\n","Epoch 15: val_loss improved from 0.03419 to 0.03418, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.03418\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.03207144886255264, 0.17908503115177155] and test accuracy: [0.049596790224313736, 0.22270336747169495]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.07463, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.07463 to 0.05752, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.05752 to 0.04833, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.04833 to 0.04302, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.04302 to 0.04000, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.04000 to 0.03805, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03805 to 0.03700, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03700 to 0.03621, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03621 to 0.03580, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03580 to 0.03557, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03557 to 0.03547, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03547 to 0.03536, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03536 to 0.03522, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.03522\n","\n","Epoch 15: val_loss improved from 0.03522 to 0.03517, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03517 to 0.03508, saving model to best_model.h5\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.032932382076978683, 0.1814728081226349] and test accuracy: [0.04888056591153145, 0.22108949720859528]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"Jmc5E5zhxD2q","executionInfo":{"status":"ok","timestamp":1670648834580,"user_tz":360,"elapsed":121,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"9665e5e8-35ee-4ea9-ff96-3aa7fecaa34c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","2  True  False  False  16  16  0.2   \n","1  True  False  False  16   8  0.2   \n","5  True  False  False  32  16  0.2   \n","0  True  False  False  16   4  0.2   \n","4  True  False  False  32   8  0.2   \n","3  True  False  False  32   4  0.2   \n","\n","                                             6  \\\n","2   [0.03252781182527542, 0.18035468459129333]   \n","1  [0.031671538949012756, 0.17796500027179718]   \n","5   [0.032932382076978683, 0.1814728081226349]   \n","0  [0.032101985067129135, 0.17917026579380035]   \n","4   [0.03207144886255264, 0.17908503115177155]   \n","3  [0.031417105346918106, 0.17724871635437012]   \n","\n","                                             7  \n","2   [0.04450133815407753, 0.21095339953899384]  \n","1   [0.04842395335435867, 0.22005443274974823]  \n","5   [0.04888056591153145, 0.22108949720859528]  \n","0   [0.049034446477890015, 0.2214372307062149]  \n","4  [0.049596790224313736, 0.22270336747169495]  \n","3   [0.04960188269615173, 0.22271479666233063]  "],"text/html":["\n","  <div id=\"df-80176c69-8956-46b3-a4d9-a709082fef0a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.03252781182527542, 0.18035468459129333]</td>\n","      <td>[0.04450133815407753, 0.21095339953899384]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.031671538949012756, 0.17796500027179718]</td>\n","      <td>[0.04842395335435867, 0.22005443274974823]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.032932382076978683, 0.1814728081226349]</td>\n","      <td>[0.04888056591153145, 0.22108949720859528]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.032101985067129135, 0.17917026579380035]</td>\n","      <td>[0.049034446477890015, 0.2214372307062149]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.03207144886255264, 0.17908503115177155]</td>\n","      <td>[0.049596790224313736, 0.22270336747169495]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.031417105346918106, 0.17724871635437012]</td>\n","      <td>[0.04960188269615173, 0.22271479666233063]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80176c69-8956-46b3-a4d9-a709082fef0a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80176c69-8956-46b3-a4d9-a709082fef0a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80176c69-8956-46b3-a4d9-a709082fef0a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3nBhlL0xD2r","executionInfo":{"status":"ok","timestamp":1670648835293,"user_tz":360,"elapsed":336,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"aedc43a4-00a9-4eff-a1f8-1ba3b6206343"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 0s 18ms/step - loss: 0.0473\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcDOsytfxD2r","executionInfo":{"status":"ok","timestamp":1670648836053,"user_tz":360,"elapsed":2,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"8446c185-a984-473e-8a7d-6d204afc4d3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 16\n"," n_batch_size = 16\n"," dropout = 0.2\n","**************************\n","Results After Tunning:\n"," Test Set RMSE: [0.0445 0.211 ]\n","\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')"]},{"cell_type":"markdown","metadata":{"id":"hn0O62FAVXrz"},"source":["## Using RMSprop optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03Hzfn2KxE3L"},"outputs":[],"source":["\n","def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'RMSprop', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stop, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXG3ByJVxE3P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670649762201,"user_tz":360,"elapsed":867796,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"db4c49b1-5207-47e1-a0a1-a5affacd13ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03418, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03418 to 0.03103, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03103 to 0.02796, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02796\n","\n","Epoch 5: val_loss improved from 0.02796 to 0.02628, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02628\n","\n","Epoch 7: val_loss did not improve from 0.02628\n","\n","Epoch 8: val_loss improved from 0.02628 to 0.02437, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02437 to 0.02313, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02313 to 0.02274, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02274 to 0.02181, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02181 to 0.02159, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02159 to 0.02123, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02123 to 0.02070, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.02070 to 0.01957, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.01957\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.019425850361585617, 0.1393766552209854] and test accuracy: [0.04339641332626343, 0.2083180546760559]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03634, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03634 to 0.03268, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03268 to 0.03011, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03011 to 0.02832, saving model to best_model.h5\n","\n","Epoch 5: val_loss did not improve from 0.02832\n","\n","Epoch 6: val_loss improved from 0.02832 to 0.02744, saving model to best_model.h5\n","\n","Epoch 7: val_loss did not improve from 0.02744\n","\n","Epoch 8: val_loss did not improve from 0.02744\n","\n","Epoch 9: val_loss did not improve from 0.02744\n","\n","Epoch 10: val_loss improved from 0.02744 to 0.02621, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02621\n","\n","Epoch 12: val_loss did not improve from 0.02621\n","\n","Epoch 13: val_loss improved from 0.02621 to 0.02523, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02523 to 0.02521, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02521\n","\n","Epoch 16: val_loss did not improve from 0.02521\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.02362865023314953, 0.15371613204479218] and test accuracy: [0.04656771570444107, 0.21579554677009583]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04268, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04268 to 0.03496, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03496 to 0.03408, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03408 to 0.03318, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03318 to 0.03181, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.03181\n","\n","Epoch 7: val_loss improved from 0.03181 to 0.02897, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02897 to 0.02817, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02817\n","\n","Epoch 10: val_loss did not improve from 0.02817\n","\n","Epoch 11: val_loss improved from 0.02817 to 0.02676, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02676\n","\n","Epoch 13: val_loss did not improve from 0.02676\n","\n","Epoch 14: val_loss improved from 0.02676 to 0.02577, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02577\n","\n","Epoch 16: val_loss improved from 0.02577 to 0.02531, saving model to best_model.h5\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.02388612926006317, 0.15455138683319092] and test accuracy: [0.0656777173280716, 0.2562766373157501]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03257, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03257 to 0.03098, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03098 to 0.02648, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.02648 to 0.02582, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02582 to 0.02557, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02557 to 0.02242, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02242 to 0.02179, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02179 to 0.02051, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02051 to 0.01907, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.01907 to 0.01892, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.01892\n","\n","Epoch 12: val_loss improved from 0.01892 to 0.01736, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.01736 to 0.01554, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.01554 to 0.01504, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.01504 to 0.01485, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.01485 to 0.01372, saving model to best_model.h5\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.011790802702307701, 0.10858546197414398] and test accuracy: [0.06113841384649277, 0.24726183712482452]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03541, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03541 to 0.02995, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.02995 to 0.02829, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.02829 to 0.02713, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02713 to 0.02598, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02598 to 0.02590, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02590 to 0.02434, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02434\n","\n","Epoch 9: val_loss did not improve from 0.02434\n","\n","Epoch 10: val_loss improved from 0.02434 to 0.02221, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02221\n","\n","Epoch 12: val_loss improved from 0.02221 to 0.02126, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02126\n","\n","Epoch 14: val_loss did not improve from 0.02126\n","\n","Epoch 15: val_loss improved from 0.02126 to 0.01975, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.01975 to 0.01774, saving model to best_model.h5\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.01622249186038971, 0.1273675411939621] and test accuracy: [0.06199387460947037, 0.24898569285869598]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04084, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04084 to 0.03610, saving model to best_model.h5\n","\n","Epoch 3: val_loss did not improve from 0.03610\n","\n","Epoch 4: val_loss improved from 0.03610 to 0.02937, saving model to best_model.h5\n","\n","Epoch 5: val_loss did not improve from 0.02937\n","\n","Epoch 6: val_loss did not improve from 0.02937\n","\n","Epoch 7: val_loss improved from 0.02937 to 0.02667, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02667 to 0.02627, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02627\n","\n","Epoch 10: val_loss did not improve from 0.02627\n","\n","Epoch 11: val_loss improved from 0.02627 to 0.02435, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02435 to 0.02422, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02422\n","\n","Epoch 14: val_loss improved from 0.02422 to 0.02405, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.02405 to 0.02303, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.02303 to 0.02216, saving model to best_model.h5\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.02144523523747921, 0.14644192159175873] and test accuracy: [0.08240720629692078, 0.2870665490627289]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbbWNc7JxE3R","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1670649832369,"user_tz":360,"elapsed":128,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"951dde55-70c9-4085-d7f4-92543ae1cce2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","0  True  False  False  16   4  0.2   \n","1  True  False  False  16   8  0.2   \n","3  True  False  False  32   4  0.2   \n","4  True  False  False  32   8  0.2   \n","2  True  False  False  16  16  0.2   \n","5  True  False  False  32  16  0.2   \n","\n","                                             6  \\\n","0   [0.019425850361585617, 0.1393766552209854]   \n","1   [0.02362865023314953, 0.15371613204479218]   \n","3  [0.011790802702307701, 0.10858546197414398]   \n","4    [0.01622249186038971, 0.1273675411939621]   \n","2   [0.02388612926006317, 0.15455138683319092]   \n","5   [0.02144523523747921, 0.14644192159175873]   \n","\n","                                            7  \n","0   [0.04339641332626343, 0.2083180546760559]  \n","1  [0.04656771570444107, 0.21579554677009583]  \n","3  [0.06113841384649277, 0.24726183712482452]  \n","4  [0.06199387460947037, 0.24898569285869598]  \n","2    [0.0656777173280716, 0.2562766373157501]  \n","5   [0.08240720629692078, 0.2870665490627289]  "],"text/html":["\n","  <div id=\"df-ed5b17c8-fa68-4e28-8f0a-949d890c645b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.019425850361585617, 0.1393766552209854]</td>\n","      <td>[0.04339641332626343, 0.2083180546760559]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.02362865023314953, 0.15371613204479218]</td>\n","      <td>[0.04656771570444107, 0.21579554677009583]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.011790802702307701, 0.10858546197414398]</td>\n","      <td>[0.06113841384649277, 0.24726183712482452]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.01622249186038971, 0.1273675411939621]</td>\n","      <td>[0.06199387460947037, 0.24898569285869598]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.02388612926006317, 0.15455138683319092]</td>\n","      <td>[0.0656777173280716, 0.2562766373157501]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.02144523523747921, 0.14644192159175873]</td>\n","      <td>[0.08240720629692078, 0.2870665490627289]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5b17c8-fa68-4e28-8f0a-949d890c645b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed5b17c8-fa68-4e28-8f0a-949d890c645b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed5b17c8-fa68-4e28-8f0a-949d890c645b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvYUda50xE3S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670649833344,"user_tz":360,"elapsed":433,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"e13f5a81-12a4-47a8-8d5c-2ab57f315e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 0s 19ms/step - loss: 0.0473\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTKYPV9GxE3T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670649833752,"user_tz":360,"elapsed":2,"user":{"displayName":"Saiharshith Karuneegar Ramesh","userId":"09737880796951428540"}},"outputId":"e7d20810-fb64-446a-bdbb-29a6896869e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 16\n"," n_batch_size = 4\n"," dropout = 0.2\n","**************************\n","Results After Tunning:\n"," Test Set RMSE: [0.0434 0.2083]\n","\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')"]},{"cell_type":"markdown","metadata":{"id":"OjWvwvCWDP-W"},"source":[]},{"cell_type":"markdown","metadata":{"id":"W-fNBBMXVgOb"},"source":["#Final Model"]},{"cell_type":"markdown","metadata":{"id":"nAfl7WH4_F38"},"source":["The Final Model:  https://colab.research.google.com/drive/14Fq49KLq_1NmmDqKbqaYsdfRpmGLd-PD#scrollTo=aDhIjMHrngxn\n","\n"]}],"metadata":{"colab":{"collapsed_sections":["kYoI8KjsVA7j","UeqzrN95VLzH","hn0O62FAVXrz"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}