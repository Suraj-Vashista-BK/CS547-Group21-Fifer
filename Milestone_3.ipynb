{"cells":[{"cell_type":"markdown","source":["# Importing Libraries"],"metadata":{"id":"VVWVysITSiAP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTZjTTGtRJKq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import seaborn as sns\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","import warnings\n","import random\n","import os\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dropout, GRU\n","import itertools\n","from sklearn.preprocessing import MinMaxScaler\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["# Data Loading And Preprocessing"],"metadata":{"id":"5_Uaehe4SrI2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"elapsed":2440,"status":"ok","timestamp":1670624242834,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"nfYggC79Ricf","outputId":"4e640e5e-6d6b-4b0e-8ff8-5616d2b5fcf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["local file not found; accessing Google Drive\n"]},{"output_type":"execute_result","data":{"text/plain":["          Area Type                           Area Name         Date  Year   \\\n","0              State                          California  01/01/1976   1976   \n","1              State                          California  01/01/1976   1976   \n","2             County                  Los Angeles County  01/01/1976   1976   \n","3             County                  Los Angeles County  01/01/1976   1976   \n","4  Metropolitan Area  Los Angeles-Long Beach-Glendale MD  01/01/1976   1976   \n","\n","     Month Seasonally Adjusted (Y/N)  Status (Preliminary / Final)   \\\n","0  January                          N                         Final   \n","1  January                          Y                         Final   \n","2  January                          N                         Final   \n","3  January                          Y                         Final   \n","4  January                          N                         Final   \n","\n","   Labor Force  Employment   Unemployment   Unemployment Rate   \n","0      9672362      8668016        1004346               0.104  \n","1      9774280      8875685         898595               0.092  \n","2      3364151      3040058         324093               0.096  \n","3      3381856      3081806         300050               0.089  \n","4      3364151      3040058         324093               0.096  "],"text/html":["\n","  <div id=\"df-4528ff47-e44f-4839-bfff-870675834746\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area Type</th>\n","      <th>Area Name</th>\n","      <th>Date</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Seasonally Adjusted (Y/N)</th>\n","      <th>Status (Preliminary / Final)</th>\n","      <th>Labor Force</th>\n","      <th>Employment</th>\n","      <th>Unemployment</th>\n","      <th>Unemployment Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>9672362</td>\n","      <td>8668016</td>\n","      <td>1004346</td>\n","      <td>0.104</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>9774280</td>\n","      <td>8875685</td>\n","      <td>898595</td>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>3381856</td>\n","      <td>3081806</td>\n","      <td>300050</td>\n","      <td>0.089</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metropolitan Area</td>\n","      <td>Los Angeles-Long Beach-Glendale MD</td>\n","      <td>01/01/1976</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4528ff47-e44f-4839-bfff-870675834746')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4528ff47-e44f-4839-bfff-870675834746 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4528ff47-e44f-4839-bfff-870675834746');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["# Try to load the dataset from the local file, If not possible, then defaults to google drive version\n","def getfile(location_pair,**kwargs):\n","    (loc,gdrive)=location_pair\n","    try:\n","        out=pd.read_csv(loc,**kwargs)\n","    except FileNotFoundError:\n","        print(\"local file not found; accessing Google Drive\")\n","        loc = 'https://drive.google.com/uc?export=download&id='+gdrive.split('/')[-2]\n","        out = pd.read_csv(loc,**kwargs)\n","    return out\n","\n","fname=(\"Local_Area_Unemployment_Statistics__LAUS_.csv\",\"https://drive.google.com/file/d/1xoDHEKiN-y4QyZNET8SdlVRSsgW_7TLy/view?usp=sharing\")\n","raw_data=getfile(fname)\n","raw_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1670624246416,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"wiDTSePiSnBI","outputId":"2ee8a6ac-0b5d-48da-c5e8-4afc544c9b1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Area Type                           Area Name        Date  Year   \\\n","0              State                          California 1976-01-01   1976   \n","1              State                          California 1976-01-01   1976   \n","2             County                  Los Angeles County 1976-01-01   1976   \n","3             County                  Los Angeles County 1976-01-01   1976   \n","4  Metropolitan Area  Los Angeles-Long Beach-Glendale MD 1976-01-01   1976   \n","\n","     Month Seasonally Adjusted (Y/N)  Status (Preliminary / Final)   \\\n","0  January                          N                         Final   \n","1  January                          Y                         Final   \n","2  January                          N                         Final   \n","3  January                          Y                         Final   \n","4  January                          N                         Final   \n","\n","   Labor Force  Employment   Unemployment   Unemployment Rate   \\\n","0      9672362      8668016        1004346               0.104   \n","1      9774280      8875685         898595               0.092   \n","2      3364151      3040058         324093               0.096   \n","3      3381856      3081806         300050               0.089   \n","4      3364151      3040058         324093               0.096   \n","\n","                   ts  Employment Rate  \n","0  189302400000000000         0.896163  \n","1  189302400000000000         0.908065  \n","2  189302400000000000         0.903663  \n","3  189302400000000000         0.911277  \n","4  189302400000000000         0.903663  "],"text/html":["\n","  <div id=\"df-c2ae63ca-3852-4dda-83a7-7db80dc2375e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area Type</th>\n","      <th>Area Name</th>\n","      <th>Date</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Seasonally Adjusted (Y/N)</th>\n","      <th>Status (Preliminary / Final)</th>\n","      <th>Labor Force</th>\n","      <th>Employment</th>\n","      <th>Unemployment</th>\n","      <th>Unemployment Rate</th>\n","      <th>ts</th>\n","      <th>Employment Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>9672362</td>\n","      <td>8668016</td>\n","      <td>1004346</td>\n","      <td>0.104</td>\n","      <td>189302400000000000</td>\n","      <td>0.896163</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State</td>\n","      <td>California</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>9774280</td>\n","      <td>8875685</td>\n","      <td>898595</td>\n","      <td>0.092</td>\n","      <td>189302400000000000</td>\n","      <td>0.908065</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","      <td>189302400000000000</td>\n","      <td>0.903663</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>County</td>\n","      <td>Los Angeles County</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>Y</td>\n","      <td>Final</td>\n","      <td>3381856</td>\n","      <td>3081806</td>\n","      <td>300050</td>\n","      <td>0.089</td>\n","      <td>189302400000000000</td>\n","      <td>0.911277</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metropolitan Area</td>\n","      <td>Los Angeles-Long Beach-Glendale MD</td>\n","      <td>1976-01-01</td>\n","      <td>1976</td>\n","      <td>January</td>\n","      <td>N</td>\n","      <td>Final</td>\n","      <td>3364151</td>\n","      <td>3040058</td>\n","      <td>324093</td>\n","      <td>0.096</td>\n","      <td>189302400000000000</td>\n","      <td>0.903663</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2ae63ca-3852-4dda-83a7-7db80dc2375e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c2ae63ca-3852-4dda-83a7-7db80dc2375e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2ae63ca-3852-4dda-83a7-7db80dc2375e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["raw_data['Date']= pd.to_datetime(raw_data['Date'])\n","raw_data['ts'] = raw_data.Date.values.astype(np.int64) # convert datetime to pandas timestamps\n","raw_data['Employment Rate']=raw_data['Employment ']/raw_data['Labor Force']\n","raw_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWlTUtY0Schk"},"outputs":[],"source":["#Loading the necessary columns\n","raw_data.columns = ['Area Type', 'Area Name', 'Date', 'Year', 'Month',\n","       'Seasonally Adjusted (Y/N)', 'Status (Preliminary / Final)',\n","       'Labor Force', 'Employment', 'Unemployment', 'Unemployment Rate','ts','Employment Rate']\n","subData_State = raw_data.loc[(raw_data['Area Type']=='State')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1670624252034,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"ZuAcw8pTUEnp","outputId":"f9b63d36-9c10-4e99-c307-eac6213fa947"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f9f58eea790>"]},"metadata":{},"execution_count":5},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Checking a plot of unemployment rate over the years\n","\n","graphPlotter = subData_State[['Date','Unemployment Rate']]\n","graphPlotter.set_index([\"Date\"], inplace=True)\n","graphPlotter.plot(title=\"California Unemployment Rate Over 45 Years\\n\", ylabel=\"rate\", xlabel=\"Year\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1670624254156,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"T5CayCAVRxO_","outputId":"77da8cd6-03c1-4d55-884c-489cd80db998"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1122 entries, 0 to 178345\n","Data columns (total 13 columns):\n"," #   Column                        Non-Null Count  Dtype         \n","---  ------                        --------------  -----         \n"," 0   Area Type                     1122 non-null   object        \n"," 1   Area Name                     1122 non-null   object        \n"," 2   Date                          1122 non-null   datetime64[ns]\n"," 3   Year                          1122 non-null   int64         \n"," 4   Month                         1122 non-null   object        \n"," 5   Seasonally Adjusted (Y/N)     1122 non-null   object        \n"," 6   Status (Preliminary / Final)  1122 non-null   object        \n"," 7   Labor Force                   1122 non-null   int64         \n"," 8   Employment                    1122 non-null   int64         \n"," 9   Unemployment                  1122 non-null   int64         \n"," 10  Unemployment Rate             1122 non-null   float64       \n"," 11  ts                            1122 non-null   int64         \n"," 12  Employment Rate               1122 non-null   float64       \n","dtypes: datetime64[ns](1), float64(2), int64(5), object(5)\n","memory usage: 122.7+ KB\n"]}],"source":["subData_State.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1670624254904,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"t6KpQObFYtHc","outputId":"0a27cc0b-06fe-4c52-ff6d-b8408b6e991c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Unemployment Rate\n","Date                         \n","1976-01-01              0.104\n","1976-01-01              0.092\n","1977-01-01              0.099\n","1977-01-01              0.092\n","1978-01-01              0.083"],"text/html":["\n","  <div id=\"df-131a6b9b-c0a2-4d1b-94f4-d3d821dea52a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unemployment Rate</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1976-01-01</th>\n","      <td>0.104</td>\n","    </tr>\n","    <tr>\n","      <th>1976-01-01</th>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>1977-01-01</th>\n","      <td>0.099</td>\n","    </tr>\n","    <tr>\n","      <th>1977-01-01</th>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>1978-01-01</th>\n","      <td>0.083</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131a6b9b-c0a2-4d1b-94f4-d3d821dea52a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-131a6b9b-c0a2-4d1b-94f4-d3d821dea52a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-131a6b9b-c0a2-4d1b-94f4-d3d821dea52a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["graphPlotter.head()"]},{"cell_type":"markdown","source":["Need comments here for upcoming cells"],"metadata":{"id":"3Axa8WDHAUNK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109,"status":"ok","timestamp":1670624280512,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"},"user_tz":360},"id":"x0mHaNbQXRu9","outputId":"b0cbfdb4-014c-4a9d-e878-b30a1d8172f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.104\n","1    0.092\n","2    0.099\n","3    0.092\n","4    0.083\n","Name: Unemployment Rate, dtype: float64"]},"metadata":{},"execution_count":8}],"source":["model_data = graphPlotter.reset_index()['Unemployment Rate']\n","model_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HPsF7aAXk2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670624281505,"user_tz":360,"elapsed":116,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"}},"outputId":"8d9b14bf-9af2-440b-a531-a52e7c71ed59"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.54761905],\n","       [0.45238095],\n","       [0.50793651],\n","       ...,\n","       [0.45238095],\n","       [0.1031746 ],\n","       [0.18253968]])"]},"metadata":{},"execution_count":9}],"source":["# using sklearn MinMaxScaler for normalizing thr data\n","scaler=MinMaxScaler(feature_range=(0,1))\n","model_data_normalized=scaler.fit_transform(np.array(model_data).reshape(-1,1))\n","model_data_normalized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBtIxOgvXxG-"},"outputs":[],"source":["training_size=int(len(model_data_normalized)*0.65)\n","test_size=len(model_data_normalized)-training_size\n","train_data,test_data=model_data_normalized[0:training_size,:],model_data_normalized[training_size:len(model_data_normalized),:1]\n","print(training_size,test_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMx3kwa-X7T4"},"outputs":[],"source":["def create_dataset(dataset, time_step=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-time_step-1):\n","        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n","        dataX.append(a)\n","        dataY.append(dataset[i + time_step, 0])\n","    return np.array(dataX), np.array(dataY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1geI8IF4YCPK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670624414976,"user_tz":360,"elapsed":116,"user":{"displayName":"Pritham Sriram Govindaraj","userId":"06490678325986000586"}},"outputId":"7cf4a8bf-5ef7-48f1-ac0d-240410efa9ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.66666667, 0.56349206, 0.53968254, ..., 0.4047619 , 0.42063492,\n","        0.28571429],\n","       [0.56349206, 0.53968254, 0.43650794, ..., 0.42063492, 0.28571429,\n","        0.3015873 ],\n","       [0.53968254, 0.43650794, 0.42857143, ..., 0.28571429, 0.3015873 ,\n","        0.17460317],\n","       ...,\n","       [0.12698413, 0.15079365, 0.06349206, ..., 0.06349206, 0.03174603,\n","        0.04761905],\n","       [0.15079365, 0.06349206, 0.07936508, ..., 0.03174603, 0.04761905,\n","        0.43650794],\n","       [0.06349206, 0.07936508, 0.03174603, ..., 0.04761905, 0.43650794,\n","        0.45238095]])"]},"metadata":{},"execution_count":13}],"source":["# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n","time_step = 100\n","X_train, y_train = create_dataset(train_data, time_step)\n","X_test, ytest = create_dataset(test_data, time_step)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, ytest.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN7Asj-4YPJR"},"outputs":[],"source":["# reshape input to be [samples, time steps, features] which is required for LSTM\n","X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"]},{"cell_type":"markdown","metadata":{"id":"1SwSbzKYBgoa"},"source":["#Traing Model using LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CqHZc438_3kY"},"outputs":[],"source":["#First model\n","model = Sequential()\n","model.add(LSTM(units=32, return_sequences=True))\n","model.add(LSTM(units=32, return_sequences=False))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69927,"status":"ok","timestamp":1670349133139,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"},"user_tz":360},"id":"510Z5VuzAFnq","outputId":"4ea44e84-acad-4ee3-87fc-4845ef1ef298"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","40/40 [==============================] - 9s 102ms/step - loss: 0.0413 - val_loss: 0.0491\n","Epoch 2/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0281 - val_loss: 0.0476\n","Epoch 3/20\n","40/40 [==============================] - 3s 79ms/step - loss: 0.0239 - val_loss: 0.0547\n","Epoch 4/20\n","40/40 [==============================] - 3s 77ms/step - loss: 0.0218 - val_loss: 0.1153\n","Epoch 5/20\n","40/40 [==============================] - 4s 94ms/step - loss: 0.0214 - val_loss: 0.0788\n","Epoch 6/20\n","40/40 [==============================] - 4s 87ms/step - loss: 0.0201 - val_loss: 0.0662\n","Epoch 7/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0186 - val_loss: 0.0744\n","Epoch 8/20\n","40/40 [==============================] - 3s 80ms/step - loss: 0.0183 - val_loss: 0.0663\n","Epoch 9/20\n","40/40 [==============================] - 3s 80ms/step - loss: 0.0171 - val_loss: 0.0941\n","Epoch 10/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0165 - val_loss: 0.1071\n","Epoch 11/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0155 - val_loss: 0.1213\n","Epoch 12/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0153 - val_loss: 0.0706\n","Epoch 13/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0141 - val_loss: 0.1115\n","Epoch 14/20\n","40/40 [==============================] - 3s 79ms/step - loss: 0.0138 - val_loss: 0.1091\n","Epoch 15/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0134 - val_loss: 0.0697\n","Epoch 16/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0134 - val_loss: 0.0767\n","Epoch 17/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0129 - val_loss: 0.0740\n","Epoch 18/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0127 - val_loss: 0.0651\n","Epoch 19/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0121 - val_loss: 0.0668\n","Epoch 20/20\n","40/40 [==============================] - 3s 78ms/step - loss: 0.0122 - val_loss: 0.0595\n"]}],"source":["model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=20,batch_size=32,verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1900,"status":"ok","timestamp":1670349137624,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"},"user_tz":360},"id":"5FvAsQ6oAW8z","outputId":"60493cf1-cecb-4a93-f459-b1e96ffd4cbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["20/20 [==============================] - 1s 20ms/step\n","10/10 [==============================] - 0s 19ms/step\n"]}],"source":["### Lets Do the prediction and check performance metrics\n","train_predict=model.predict(X_train)\n","test_predict=model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rOsGENoAW80"},"outputs":[],"source":["##Transformback to original form\n","train_predict=scaler.inverse_transform(train_predict)\n","test_predict=scaler.inverse_transform(test_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dfzqy5FDwrI"},"outputs":[],"source":["ytest = scaler.inverse_transform(np.array(ytest).reshape(-1,1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670349144292,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"},"user_tz":360},"id":"RLhBFIoS7q4I","outputId":"ca74369b-5d97-4beb-d081-ff63c842769f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2872032571206362"]},"metadata":{},"execution_count":100}],"source":["### Calculate RMSE performance metrics\n","import math\n","from sklearn.metrics import mean_squared_error\n","math.sqrt(mean_squared_error(y_train,train_predict))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670349145386,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"},"user_tz":360},"id":"WtX1KsTV7tHb","outputId":"4f458600-a3c4-4f53-8466-a63ac46deebe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.030729401237103725"]},"metadata":{},"execution_count":101}],"source":["### Test Data RMSE\n","math.sqrt(mean_squared_error(ytest,test_predict))"]},{"cell_type":"markdown","metadata":{"id":"mM21c-pixg-F"},"source":["# Hyper-Parameter Tuning with mini batch training \n"]},{"cell_type":"markdown","source":["## Using Adam optimizer"],"metadata":{"id":"kYoI8KjsVA7j"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaryftBk5YCE"},"outputs":[],"source":["\n","def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'Adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stopping, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nWQq-555YEZ","executionInfo":{"status":"ok","timestamp":1670349968353,"user_tz":360,"elapsed":817084,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"da67b29b-67dd-44a1-d010-5bf5c2456acb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03481, saving model to best_model.h5\n","\n","Epoch 2: val_loss did not improve from 0.03481\n","\n","Epoch 3: val_loss improved from 0.03481 to 0.02822, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02822\n","\n","Epoch 5: val_loss improved from 0.02822 to 0.02689, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02689\n","\n","Epoch 7: val_loss improved from 0.02689 to 0.02664, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02664 to 0.02567, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02567\n","\n","Epoch 10: val_loss improved from 0.02567 to 0.02528, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02528 to 0.02374, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02374\n","\n","Epoch 13: val_loss did not improve from 0.02374\n","\n","Epoch 14: val_loss improved from 0.02374 to 0.02298, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.02298 to 0.02195, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.02195 to 0.02085, saving model to best_model.h5\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.01934737153351307, 0.13909482955932617] and test accuracy: [0.08124330639839172, 0.28503212332725525]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03546, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03546 to 0.03515, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03515 to 0.03494, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03494 to 0.03233, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03233 to 0.02974, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02974 to 0.02771, saving model to best_model.h5\n","\n","Epoch 7: val_loss did not improve from 0.02771\n","\n","Epoch 8: val_loss improved from 0.02771 to 0.02491, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02491 to 0.02445, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02445 to 0.02392, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02392 to 0.02345, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02345\n","\n","Epoch 13: val_loss improved from 0.02345 to 0.02217, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.02217\n","\n","Epoch 15: val_loss improved from 0.02217 to 0.02180, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.02180 to 0.02092, saving model to best_model.h5\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.01944561116397381, 0.13944752514362335] and test accuracy: [0.08029636740684509, 0.2833661437034607]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03941, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03941 to 0.03551, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03551 to 0.03524, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03524 to 0.03291, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03291 to 0.03109, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03109 to 0.02887, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02887 to 0.02846, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02846 to 0.02733, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02733\n","\n","Epoch 10: val_loss improved from 0.02733 to 0.02710, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02710 to 0.02699, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02699\n","\n","Epoch 13: val_loss did not improve from 0.02699\n","\n","Epoch 14: val_loss did not improve from 0.02699\n","\n","Epoch 15: val_loss improved from 0.02699 to 0.02597, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.02597\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.024115998297929764, 0.155293270945549] and test accuracy: [0.07213375717401505, 0.2685772776603699]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03793, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03793 to 0.03477, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03477 to 0.02791, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02791\n","\n","Epoch 5: val_loss improved from 0.02791 to 0.02651, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02651 to 0.02453, saving model to best_model.h5\n","\n","Epoch 7: val_loss did not improve from 0.02453\n","\n","Epoch 8: val_loss improved from 0.02453 to 0.02364, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02364\n","\n","Epoch 10: val_loss improved from 0.02364 to 0.02110, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02110\n","\n","Epoch 12: val_loss improved from 0.02110 to 0.02033, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02033 to 0.01780, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.01780 to 0.01690, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.01690\n","\n","Epoch 16: val_loss improved from 0.01690 to 0.01580, saving model to best_model.h5\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.014585006050765514, 0.12076839804649353] and test accuracy: [0.08620065450668335, 0.2935994863510132]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03560, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03560 to 0.03333, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03333 to 0.03087, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03087 to 0.02656, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02656 to 0.02633, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02633 to 0.02578, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02578 to 0.02368, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02368 to 0.02311, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02311 to 0.02290, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02290 to 0.02191, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02191 to 0.02151, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02151 to 0.02050, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02050 to 0.01997, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.01997 to 0.01969, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.01969 to 0.01869, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.01869\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.016759539023041725, 0.12945863604545593] and test accuracy: [0.06900686025619507, 0.26269155740737915]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03662, saving model to best_model.h5\n","\n","Epoch 2: val_loss did not improve from 0.03662\n","\n","Epoch 3: val_loss improved from 0.03662 to 0.03571, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03571 to 0.03346, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03346 to 0.03029, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03029 to 0.02916, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02916 to 0.02842, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02842\n","\n","Epoch 9: val_loss did not improve from 0.02842\n","\n","Epoch 10: val_loss improved from 0.02842 to 0.02836, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02836 to 0.02704, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.02704 to 0.02462, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02462\n","\n","Epoch 14: val_loss improved from 0.02462 to 0.02427, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02427\n","\n","Epoch 16: val_loss improved from 0.02427 to 0.02279, saving model to best_model.h5\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.022155551239848137, 0.14884741604328156] and test accuracy: [0.09681986272335052, 0.3111588954925537]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"o7sca14I5YGW","executionInfo":{"status":"ok","timestamp":1670349968671,"user_tz":360,"elapsed":352,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"a66c0f6d-78c6-4387-e44a-10c5420dfb47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","4  True  False  False  32   8  0.2   \n","2  True  False  False  16  16  0.2   \n","1  True  False  False  16   8  0.2   \n","0  True  False  False  16   4  0.2   \n","3  True  False  False  32   4  0.2   \n","5  True  False  False  32  16  0.2   \n","\n","                                             6  \\\n","4  [0.016759539023041725, 0.12945863604545593]   \n","2    [0.024115998297929764, 0.155293270945549]   \n","1   [0.01944561116397381, 0.13944752514362335]   \n","0   [0.01934737153351307, 0.13909482955932617]   \n","3  [0.014585006050765514, 0.12076839804649353]   \n","5  [0.022155551239848137, 0.14884741604328156]   \n","\n","                                            7  \n","4  [0.06900686025619507, 0.26269155740737915]  \n","2   [0.07213375717401505, 0.2685772776603699]  \n","1   [0.08029636740684509, 0.2833661437034607]  \n","0  [0.08124330639839172, 0.28503212332725525]  \n","3   [0.08620065450668335, 0.2935994863510132]  \n","5   [0.09681986272335052, 0.3111588954925537]  "],"text/html":["\n","  <div id=\"df-f1c84ba3-e7cd-49f5-98c8-ac8997b2a3e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.016759539023041725, 0.12945863604545593]</td>\n","      <td>[0.06900686025619507, 0.26269155740737915]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.024115998297929764, 0.155293270945549]</td>\n","      <td>[0.07213375717401505, 0.2685772776603699]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.01944561116397381, 0.13944752514362335]</td>\n","      <td>[0.08029636740684509, 0.2833661437034607]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.01934737153351307, 0.13909482955932617]</td>\n","      <td>[0.08124330639839172, 0.28503212332725525]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.014585006050765514, 0.12076839804649353]</td>\n","      <td>[0.08620065450668335, 0.2935994863510132]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.022155551239848137, 0.14884741604328156]</td>\n","      <td>[0.09681986272335052, 0.3111588954925537]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1c84ba3-e7cd-49f5-98c8-ac8997b2a3e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f1c84ba3-e7cd-49f5-98c8-ac8997b2a3e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f1c84ba3-e7cd-49f5-98c8-ac8997b2a3e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":104}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ej16nO-tCy6y","executionInfo":{"status":"ok","timestamp":1670349968672,"user_tz":360,"elapsed":9,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"a5b18839-28b1-44f2-c518-0f3059cb64c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 0s 27ms/step - loss: 0.0595\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMY1_WTnCMsC","executionInfo":{"status":"ok","timestamp":1670349968984,"user_tz":360,"elapsed":3,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"f7abca0b-a68e-4292-89ac-3672ee62c6ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 32\n"," n_batch_size = 8\n"," dropout = 0.2\n","**************************\n","Results Before Tunning:\n"," Test Set RMSE: 0.0595\n","\n","Results After Tunning:\n"," Test Set RMSE: [0.069  0.2627]\n","\n","-342.0% Improvement\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results Before Tunning:\\n Test Set RMSE: {np.round(results, 4)}\\n')\n","print(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')\n","print(f'{np.round((results - hist.iloc[0, -1][1])*100/np.round(results, 4))}% Improvement')"]},{"cell_type":"markdown","source":["## Using Adagrad optimizer\n"],"metadata":{"id":"UeqzrN95VLzH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DVCg5CbxD2S"},"outputs":[],"source":["def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'Adagrad', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stopping, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuXHtFnjxD2p","executionInfo":{"status":"ok","timestamp":1670345795592,"user_tz":360,"elapsed":791355,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"289bb7d7-456e-4a3b-d6f0-1e29c6c69457"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.07685, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.07685 to 0.05785, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.05785 to 0.04765, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.04765 to 0.04188, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.04188 to 0.03879, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03879 to 0.03695, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03695 to 0.03598, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03598 to 0.03552, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03552 to 0.03528, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03528 to 0.03507, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03507 to 0.03493, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03493 to 0.03479, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.03479\n","\n","Epoch 14: val_loss improved from 0.03479 to 0.03475, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03475 to 0.03469, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03469 to 0.03469, saving model to best_model.h5\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.03249090164899826, 0.1802523285150528] and test accuracy: [0.06077728420495987, 0.24653048813343048]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.05910, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.05910 to 0.04339, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.04339 to 0.03830, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03830 to 0.03659, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03659 to 0.03583, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03583 to 0.03544, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03544 to 0.03532, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03532 to 0.03526, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03526 to 0.03511, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03511 to 0.03503, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.03503\n","\n","Epoch 12: val_loss improved from 0.03503 to 0.03493, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03493 to 0.03493, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03493 to 0.03486, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03486 to 0.03478, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03478 to 0.03471, saving model to best_model.h5\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.03256300836801529, 0.18045222759246826] and test accuracy: [0.062003906816244125, 0.24900583922863007]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.09854, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.09854 to 0.07671, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.07671 to 0.06316, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.06316 to 0.05411, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.05411 to 0.04798, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.04798 to 0.04378, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.04378 to 0.04087, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.04087 to 0.03890, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03890 to 0.03746, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03746 to 0.03663, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03663 to 0.03602, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03602 to 0.03569, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03569 to 0.03542, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03542 to 0.03512, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03512 to 0.03498, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03498 to 0.03482, saving model to best_model.h5\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.032532524317502975, 0.18036775290966034] and test accuracy: [0.058281343430280685, 0.24141529202461243]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.05638, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.05638 to 0.03909, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03909 to 0.03510, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03510 to 0.03377, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03377 to 0.03365, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03365 to 0.03346, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03346 to 0.03333, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03333 to 0.03330, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.03330\n","\n","Epoch 10: val_loss improved from 0.03330 to 0.03321, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03321 to 0.03319, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03319 to 0.03319, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03319 to 0.03317, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03317 to 0.03304, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.03304\n","\n","Epoch 16: val_loss did not improve from 0.03304\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.030952170491218567, 0.17593228816986084] and test accuracy: [0.0646989494562149, 0.2543598711490631]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.05717, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.05717 to 0.04208, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.04208 to 0.03719, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03719 to 0.03563, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.03563 to 0.03508, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03508 to 0.03496, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03496 to 0.03479, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03479 to 0.03475, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.03475\n","\n","Epoch 10: val_loss improved from 0.03475 to 0.03474, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.03474\n","\n","Epoch 12: val_loss did not improve from 0.03474\n","\n","Epoch 13: val_loss improved from 0.03474 to 0.03473, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03473 to 0.03469, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.03469\n","\n","Epoch 16: val_loss improved from 0.03469 to 0.03468, saving model to best_model.h5\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.03255950286984444, 0.18044252693653107] and test accuracy: [0.06303238123655319, 0.2510625123977661]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.07613, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.07613 to 0.05613, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.05613 to 0.04604, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.04604 to 0.04102, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.04102 to 0.03811, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.03811 to 0.03679, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.03679 to 0.03605, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.03605 to 0.03566, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.03566 to 0.03544, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.03544 to 0.03528, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.03528 to 0.03521, saving model to best_model.h5\n","\n","Epoch 12: val_loss improved from 0.03521 to 0.03516, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.03516 to 0.03505, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.03505 to 0.03497, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.03497 to 0.03496, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.03496 to 0.03493, saving model to best_model.h5\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.03282087296247482, 0.18116532266139984] and test accuracy: [0.06349162757396698, 0.2519754469394684]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"Jmc5E5zhxD2q","executionInfo":{"status":"ok","timestamp":1670345795592,"user_tz":360,"elapsed":42,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"b91aa9e9-04d4-43d2-f556-e1aef6f918aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","2  True  False  False  16  16  0.2   \n","0  True  False  False  16   4  0.2   \n","1  True  False  False  16   8  0.2   \n","4  True  False  False  32   8  0.2   \n","5  True  False  False  32  16  0.2   \n","3  True  False  False  32   4  0.2   \n","\n","                                             6  \\\n","2  [0.032532524317502975, 0.18036775290966034]   \n","0    [0.03249090164899826, 0.1802523285150528]   \n","1   [0.03256300836801529, 0.18045222759246826]   \n","4   [0.03255950286984444, 0.18044252693653107]   \n","5   [0.03282087296247482, 0.18116532266139984]   \n","3  [0.030952170491218567, 0.17593228816986084]   \n","\n","                                             7  \n","2  [0.058281343430280685, 0.24141529202461243]  \n","0   [0.06077728420495987, 0.24653048813343048]  \n","1  [0.062003906816244125, 0.24900583922863007]  \n","4    [0.06303238123655319, 0.2510625123977661]  \n","5    [0.06349162757396698, 0.2519754469394684]  \n","3     [0.0646989494562149, 0.2543598711490631]  "],"text/html":["\n","  <div id=\"df-b4eebd22-914a-463f-9e5d-8807897b0012\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.032532524317502975, 0.18036775290966034]</td>\n","      <td>[0.058281343430280685, 0.24141529202461243]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.03249090164899826, 0.1802523285150528]</td>\n","      <td>[0.06077728420495987, 0.24653048813343048]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.03256300836801529, 0.18045222759246826]</td>\n","      <td>[0.062003906816244125, 0.24900583922863007]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.03255950286984444, 0.18044252693653107]</td>\n","      <td>[0.06303238123655319, 0.2510625123977661]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.03282087296247482, 0.18116532266139984]</td>\n","      <td>[0.06349162757396698, 0.2519754469394684]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.030952170491218567, 0.17593228816986084]</td>\n","      <td>[0.0646989494562149, 0.2543598711490631]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4eebd22-914a-463f-9e5d-8807897b0012')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b4eebd22-914a-463f-9e5d-8807897b0012 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b4eebd22-914a-463f-9e5d-8807897b0012');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3nBhlL0xD2r","executionInfo":{"status":"ok","timestamp":1670345796155,"user_tz":360,"elapsed":571,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"642a63b2-5c48-49fb-d41d-586d73f59c45"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 0s 20ms/step - loss: 0.0943\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcDOsytfxD2r","executionInfo":{"status":"ok","timestamp":1670345796156,"user_tz":360,"elapsed":24,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"fabfd417-163e-4c17-bfa7-86a077e9350a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 16\n"," n_batch_size = 16\n"," dropout = 0.2\n","**************************\n","Results Before Tunning:\n"," Test Set RMSE: 0.0943\n","\n","Results After Tunning:\n"," Test Set RMSE: [0.0583 0.2414]\n","\n","-156.0% Improvement\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')"]},{"cell_type":"markdown","source":["## Using RMSprop optimizer"],"metadata":{"id":"hn0O62FAVXrz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"03Hzfn2KxE3L"},"outputs":[],"source":["\n","def LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest):\n","    \n","    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n","    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n","                                                  n_neurons, n_batch_size, dropout))\n","    \n","    print(possible_combinations)\n","    print('\\n')\n","    \n","    hist = []\n","    \n","    for i in range(0, len(possible_combinations)):\n","        \n","        print(f'{i+1}th combination: \\n')\n","        print('--------------------------------------------------------------------')\n","        \n","        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n","        \n","        # instantiating the model in the strategy scope creates the model on the TPU\n","        #with tpu_strategy.scope():\n","        model = Sequential()\n","        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","        model.add(Dropout(dropout))\n","\n","        if first_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if second_additional_layer:\n","            model.add(LSTM(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        if third_additional_layer:\n","            model.add(GRU(units=n_neurons, return_sequences=True))\n","            model.add(Dropout(dropout))\n","\n","        model.add(LSTM(units=n_neurons, return_sequences=False))\n","        model.add(Dropout(dropout))\n","        model.add(Dense(units=1, activation='linear'))\n","\n","        \n","        model.compile( 'RMSprop', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","        early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","        '''''\n","        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n","        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n","        '''''\n","\n","        file_path = 'best_model.h5'\n","\n","        model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","        model.fit(X_train, y_train, validation_split=0.3, epochs=16, batch_size=n_batch_size, callbacks=[early_stop, model_checkpoint], verbose=0)\n","\n","        # load the best model\n","        # regressor = load_model('best_model.h5')\n","\n","        train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","        test_accuracy = model.evaluate(X_test, ytest, verbose=0)\n","\n","        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n","                          train_accuracy, test_accuracy)))\n","\n","        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n","        \n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","        print('--------------------------------------------------------------------')\n","         \n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXG3ByJVxE3P","executionInfo":{"status":"ok","timestamp":1670346665755,"user_tz":360,"elapsed":869613,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"c529d103-0213-4a23-c408-2aded339a59c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(True, False, False, 16, 4, 0.2), (True, False, False, 16, 8, 0.2), (True, False, False, 16, 16, 0.2), (True, False, False, 32, 4, 0.2), (True, False, False, 32, 8, 0.2), (True, False, False, 32, 16, 0.2)]\n","\n","\n","1th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03567, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03567 to 0.03306, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03306 to 0.02879, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02879\n","\n","Epoch 5: val_loss improved from 0.02879 to 0.02837, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02837\n","\n","Epoch 7: val_loss improved from 0.02837 to 0.02619, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02619\n","\n","Epoch 9: val_loss did not improve from 0.02619\n","\n","Epoch 10: val_loss improved from 0.02619 to 0.02493, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02493\n","\n","Epoch 12: val_loss improved from 0.02493 to 0.02320, saving model to best_model.h5\n","\n","Epoch 13: val_loss improved from 0.02320 to 0.02201, saving model to best_model.h5\n","\n","Epoch 14: val_loss did not improve from 0.02201\n","\n","Epoch 15: val_loss improved from 0.02201 to 0.02125, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.02125 to 0.02079, saving model to best_model.h5\n","0-th combination = (True, False, False, 16, 4, 0.2) \n"," train accuracy: [0.0193770881742239, 0.13920161128044128] and test accuracy: [0.08000601828098297, 0.282853364944458]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","2th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03557, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03557 to 0.03335, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03335 to 0.03081, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03081 to 0.02814, saving model to best_model.h5\n","\n","Epoch 5: val_loss improved from 0.02814 to 0.02700, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02700\n","\n","Epoch 7: val_loss did not improve from 0.02700\n","\n","Epoch 8: val_loss improved from 0.02700 to 0.02562, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02562\n","\n","Epoch 10: val_loss improved from 0.02562 to 0.02500, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02500 to 0.02438, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02438\n","\n","Epoch 13: val_loss improved from 0.02438 to 0.02307, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02307 to 0.02268, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02268\n","\n","Epoch 16: val_loss improved from 0.02268 to 0.02160, saving model to best_model.h5\n","1-th combination = (True, False, False, 16, 8, 0.2) \n"," train accuracy: [0.02024386264383793, 0.1422809213399887] and test accuracy: [0.07669618725776672, 0.2769407629966736]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","3th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04185, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04185 to 0.03839, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03839 to 0.03405, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.03405\n","\n","Epoch 5: val_loss improved from 0.03405 to 0.02990, saving model to best_model.h5\n","\n","Epoch 6: val_loss improved from 0.02990 to 0.02880, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02880 to 0.02803, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02803 to 0.02713, saving model to best_model.h5\n","\n","Epoch 9: val_loss did not improve from 0.02713\n","\n","Epoch 10: val_loss did not improve from 0.02713\n","\n","Epoch 11: val_loss did not improve from 0.02713\n","\n","Epoch 12: val_loss did not improve from 0.02713\n","\n","Epoch 13: val_loss improved from 0.02713 to 0.02711, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02711 to 0.02582, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.02582\n","\n","Epoch 16: val_loss did not improve from 0.02582\n","2-th combination = (True, False, False, 16, 16, 0.2) \n"," train accuracy: [0.024121489375829697, 0.15531094372272491] and test accuracy: [0.07086361199617386, 0.2662022113800049]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","4th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.04438, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.04438 to 0.03145, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03145 to 0.02800, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02800\n","\n","Epoch 5: val_loss improved from 0.02800 to 0.02536, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02536\n","\n","Epoch 7: val_loss improved from 0.02536 to 0.02442, saving model to best_model.h5\n","\n","Epoch 8: val_loss improved from 0.02442 to 0.02391, saving model to best_model.h5\n","\n","Epoch 9: val_loss improved from 0.02391 to 0.01975, saving model to best_model.h5\n","\n","Epoch 10: val_loss did not improve from 0.01975\n","\n","Epoch 11: val_loss improved from 0.01975 to 0.01819, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.01819\n","\n","Epoch 13: val_loss improved from 0.01819 to 0.01728, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.01728 to 0.01681, saving model to best_model.h5\n","\n","Epoch 15: val_loss improved from 0.01681 to 0.01497, saving model to best_model.h5\n","\n","Epoch 16: val_loss improved from 0.01497 to 0.01389, saving model to best_model.h5\n","3-th combination = (True, False, False, 32, 4, 0.2) \n"," train accuracy: [0.012626159004867077, 0.11236618459224701] and test accuracy: [0.093537338078022, 0.3058387339115143]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","5th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03544, saving model to best_model.h5\n","\n","Epoch 2: val_loss did not improve from 0.03544\n","\n","Epoch 3: val_loss improved from 0.03544 to 0.02907, saving model to best_model.h5\n","\n","Epoch 4: val_loss did not improve from 0.02907\n","\n","Epoch 5: val_loss improved from 0.02907 to 0.02684, saving model to best_model.h5\n","\n","Epoch 6: val_loss did not improve from 0.02684\n","\n","Epoch 7: val_loss improved from 0.02684 to 0.02591, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02591\n","\n","Epoch 9: val_loss did not improve from 0.02591\n","\n","Epoch 10: val_loss improved from 0.02591 to 0.02263, saving model to best_model.h5\n","\n","Epoch 11: val_loss improved from 0.02263 to 0.02212, saving model to best_model.h5\n","\n","Epoch 12: val_loss did not improve from 0.02212\n","\n","Epoch 13: val_loss improved from 0.02212 to 0.02032, saving model to best_model.h5\n","\n","Epoch 14: val_loss improved from 0.02032 to 0.01949, saving model to best_model.h5\n","\n","Epoch 15: val_loss did not improve from 0.01949\n","\n","Epoch 16: val_loss improved from 0.01949 to 0.01848, saving model to best_model.h5\n","4-th combination = (True, False, False, 32, 8, 0.2) \n"," train accuracy: [0.017180608585476875, 0.13107481598854065] and test accuracy: [0.08215011656284332, 0.2866184115409851]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","6th combination: \n","\n","--------------------------------------------------------------------\n","\n","Epoch 1: val_loss improved from inf to 0.03772, saving model to best_model.h5\n","\n","Epoch 2: val_loss improved from 0.03772 to 0.03417, saving model to best_model.h5\n","\n","Epoch 3: val_loss improved from 0.03417 to 0.03032, saving model to best_model.h5\n","\n","Epoch 4: val_loss improved from 0.03032 to 0.02774, saving model to best_model.h5\n","\n","Epoch 5: val_loss did not improve from 0.02774\n","\n","Epoch 6: val_loss improved from 0.02774 to 0.02756, saving model to best_model.h5\n","\n","Epoch 7: val_loss improved from 0.02756 to 0.02669, saving model to best_model.h5\n","\n","Epoch 8: val_loss did not improve from 0.02669\n","\n","Epoch 9: val_loss improved from 0.02669 to 0.02633, saving model to best_model.h5\n","\n","Epoch 10: val_loss improved from 0.02633 to 0.02508, saving model to best_model.h5\n","\n","Epoch 11: val_loss did not improve from 0.02508\n","\n","Epoch 12: val_loss improved from 0.02508 to 0.02288, saving model to best_model.h5\n","\n","Epoch 13: val_loss did not improve from 0.02288\n","\n","Epoch 14: val_loss did not improve from 0.02288\n","\n","Epoch 15: val_loss improved from 0.02288 to 0.02114, saving model to best_model.h5\n","\n","Epoch 16: val_loss did not improve from 0.02114\n","5-th combination = (True, False, False, 32, 16, 0.2) \n"," train accuracy: [0.022302171215415, 0.14933910965919495] and test accuracy: [0.054144151508808136, 0.23268896341323853]\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n","--------------------------------------------------------------------\n"]}],"source":["config = [[True], [False], [False], [16, 32], [4, 8, 16], [0.2]]\n","\n","#['RMSprop', 'Adam', 'Adagrad']\n","\n","#list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n","\n","hist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, ytest)  # change x_train shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"zbbWNc7JxE3R","executionInfo":{"status":"ok","timestamp":1670346665756,"user_tz":360,"elapsed":19,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"ef48a546-1663-420e-de6b-7b411d1551bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      0      1      2   3   4    5  \\\n","5  True  False  False  32  16  0.2   \n","2  True  False  False  16  16  0.2   \n","1  True  False  False  16   8  0.2   \n","0  True  False  False  16   4  0.2   \n","4  True  False  False  32   8  0.2   \n","3  True  False  False  32   4  0.2   \n","\n","                                             6  \\\n","5     [0.022302171215415, 0.14933910965919495]   \n","2  [0.024121489375829697, 0.15531094372272491]   \n","1    [0.02024386264383793, 0.1422809213399887]   \n","0    [0.0193770881742239, 0.13920161128044128]   \n","4  [0.017180608585476875, 0.13107481598854065]   \n","3  [0.012626159004867077, 0.11236618459224701]   \n","\n","                                             7  \n","5  [0.054144151508808136, 0.23268896341323853]  \n","2    [0.07086361199617386, 0.2662022113800049]  \n","1    [0.07669618725776672, 0.2769407629966736]  \n","0     [0.08000601828098297, 0.282853364944458]  \n","4    [0.08215011656284332, 0.2866184115409851]  \n","3      [0.093537338078022, 0.3058387339115143]  "],"text/html":["\n","  <div id=\"df-55eae8f7-a894-4066-89d6-0e67ecf0c171\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.022302171215415, 0.14933910965919495]</td>\n","      <td>[0.054144151508808136, 0.23268896341323853]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.2</td>\n","      <td>[0.024121489375829697, 0.15531094372272491]</td>\n","      <td>[0.07086361199617386, 0.2662022113800049]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.02024386264383793, 0.1422809213399887]</td>\n","      <td>[0.07669618725776672, 0.2769407629966736]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.0193770881742239, 0.13920161128044128]</td>\n","      <td>[0.08000601828098297, 0.282853364944458]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>[0.017180608585476875, 0.13107481598854065]</td>\n","      <td>[0.08215011656284332, 0.2866184115409851]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>[0.012626159004867077, 0.11236618459224701]</td>\n","      <td>[0.093537338078022, 0.3058387339115143]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55eae8f7-a894-4066-89d6-0e67ecf0c171')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55eae8f7-a894-4066-89d6-0e67ecf0c171 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55eae8f7-a894-4066-89d6-0e67ecf0c171');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":55}],"source":["hist = pd.DataFrame(hist)\n","hist = hist.sort_values(by=[7], ascending=True)\n","hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvYUda50xE3S","executionInfo":{"status":"ok","timestamp":1670346666051,"user_tz":360,"elapsed":303,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"deed3750-2b57-43b9-dbee-7eca79f48ecb"},"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 0s 20ms/step - loss: 0.0943\n"]}],"source":["results = model.evaluate(X_test, ytest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTKYPV9GxE3T","executionInfo":{"status":"ok","timestamp":1670346666052,"user_tz":360,"elapsed":10,"user":{"displayName":"Maahi Patel","userId":"13370495156593526640"}},"outputId":"e9856ed4-6c37-4d1c-d4bb-03e79e6957de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Combination: \n"," first_additional_layer = True\n"," second_additional_layer = False\n"," third_additional_layer = False\n"," n_neurons = 32\n"," n_batch_size = 16\n"," dropout = 0.2\n","**************************\n","Results Before Tunning:\n"," Test Set RMSE: 0.0943\n","\n","Results After Tunning:\n"," Test Set RMSE: [0.0541 0.2327]\n","\n","-147.0% Improvement\n"]}],"source":["print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\n","print('**************************')\n","print(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)}\\n')"]},{"cell_type":"markdown","source":["#Final Model"],"metadata":{"id":"W-fNBBMXVgOb"}},{"cell_type":"markdown","metadata":{"id":"nAfl7WH4_F38"},"source":["The Final Model:  https://colab.research.google.com/drive/14Fq49KLq_1NmmDqKbqaYsdfRpmGLd-PD#scrollTo=aDhIjMHrngxn\n","\n"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["kYoI8KjsVA7j","UeqzrN95VLzH","hn0O62FAVXrz"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}